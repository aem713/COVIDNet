# -*- coding: utf-8 -*-
"""HandcraftedFeatures

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YC5JRyMZCHNWbpTAO6Fq9OmZhuU6M1MK
"""

import librosa
import numpy as np
import scipy
from sklearn.decomposition import PCA
import random
from tensorflow.keras import layers, datasets, models, Model
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras.models import Sequential
from tensorflow import keras
import scipy
from tensorflow.keras.layers import Dense, Flatten, InputLayer, Input

SAMPLING_RATE = Parameters.SAMPLING_RATE
DURATION = Parameters.DURATION
NUM_MELS = Parameters.NUM_MELS
FMAX = Parameters.FMAX
TOP_DB = Parameters.TOP_DB
EPS = Parameters.EPS
N_MFCC = Parameters.N_MFCC

def myfunction():
  """
  Returns the value 0.35 as an input to the random.shuffle() function
  inputs:
    - N/A
  outputs:
    - the number 0.35
  """
  return 0.35

def get_zero_crossing(audio):
  """
  Returns the sum of the zero crossings of the input audio
  inputs:
    - audio: the audio file
  outputs:
    - the sum of the zero crossings of audio
  """
  return sum(librosa.zero_crossings(audio, pad=False))
  
def get_spectral_centroid(audio):
  """
  Returns the spectral centroid of the input audio
  inputs:
    - audio: the audio file
    - pad: a boolean specifying whether to pad the audio or not
  outputs:
    - the spectral centroid of audio
  """
  return librosa.feature.spectral_centroid(audio, sr=SAMPLING_RATE)[0]
  
def get_tempo(audio):
  """
  Returns the tempo of the input audio
  inputs:
    - audio: the audio file
  outputs:
    - the tempo of the audio
  """
  return librosa.beat.tempo(audio)
  
def get_onset_frames(audio):
  """
  Computes a spectral flux onset strength envelope
  inputs:
    - audio: the audio file
  outputs:
    - vector containing the onset strength envelope
  """
  return librosa.onset.onset_strength(audio, sr = SAMPLING_RATE)

def get_duration(audio):
  """
  Computes the duration (in seconds) of the audio
  inputs:
    - audio: the audio file
    - sr: the sampling rate
  outputs:
    - the duration (in seconds) of the audio 
  """
  return librosa.get_duration(audio, sr=SAMPLING_RATE)

def get_period():
  """
  Computes the period
  inputs:
    - N/A
  outputs:
    - the period of the signal
  """
  return 1/SAMPLING_RATE
 
def get_spectral_rolloff(audio):
  """
  Computes the spectral rolloff of the audio
  inputs:
    - audio: the audio file
  outputs:
    - the roll-off frequency for each frame of audio
  """
  return librosa.feature.spectral_rolloff(audio, sr=SAMPLING_RATE)[0]

def get_rms(audio):
  """
  Computes the rms of the audio
  inputs:
    - audio: the audio file
  outputs:
    - the rms of the audio 
  """
  return librosa.feature.rms(audio)
  
def get_mfcc_13(audio):
  """
  Computes the Mel-frequency cepstral coefficients (MFCCs)
  inputs:
    - audio: the audio file
  outputs:
    - the MFCC sequence
  """
  return librosa.feature.mfcc(audio, sr = SAMPLING_RATE, n_mfcc=N_MFCC)
  
def get_mfcc_delta(x):
  """
  Computes delta features: local estimate of the derivative of the input data 
  along the first axis.
  inputs:
    - x: the input signal
  outputs:
    - the delta matrix of data at the first order
  """
  return librosa.feature.delta(x, order=1)
  
def get_mfcc_delta2(x):
  """
  Computes delta features: local estimate of the derivative of the input data 
  along the second axis.
  inputs:
    - x: the input signal
  outputs:
    - delta matrix of data at the second order
  """
  return librosa.feature.delta(x, order=2)

def get_stats(array):
  """
  Computes various handcrafted features of the input array along the 0th axis
  inputs:
    - array: the input signal
  outputs:
    - a numpy hstack of the various feature vectors
  """
  #In a two-dimensional vector, the elements of axis 0 are rows and the elements of axis 1 are columns.
  
  mean = np.mean(array.T, axis=0) # Mean
  median = np.median(array.T, axis=0) # Median
  rms_vector = np.sqrt(np.mean(np.square(array).T, axis=0)) # RMS
  max = np.max(array.T, axis=0) # Max
  min = np.min(array.T, axis=0) # Min
  first_quantile = np.quantile(array.T, 0.25, axis=0) # First quantile
  third_quantile = np.quantile(array.T, 0.75, axis=0) # Third quantile
  interquantile_range = np.subtract(*np.percentile(array.T, [75, 25], axis=0)) # Interquartile range
  std = np.std(array.T, axis=0) # Standard Deviation
  skew = scipy.stats.skew(array.T, axis=0, bias=True) # Skew
  kurtosis = scipy.stats.kurtosis(array.T, axis=0) # Kurtosis

  return np.hstack([mean, median, rms_vector, max, min, first_quantile, third_quantile, interquantile_range, std, skew, kurtosis])

def get_stats2(array):
  """
  Computes various handcrafted features of the input array along the default axis
  inputs:
    - array: the input signal
  outputs:
    - a numpy hstack of the various feature vectors
  """
  mean = np.mean(array) # Mean
  median = np.median(array) # Median
  rms_vector = np.sqrt(np.mean(np.square(array))) # RMS
  max = np.max(array) # Max
  min = np.min(array) # Min
  first_quantile = np.quantile(array, 0.25) # First quantile
  third_quantile = np.quantile(array, 0.75) # Third quantile
  interquantile_range = np.subtract(*np.percentile(array, [75, 25])) # Interquartile range
  std = np.std(array) # Standard Deviation
  skew = scipy.stats.skew(array, axis=None, bias=True) # Skew
  kurtosis = scipy.stats.kurtosis(array, axis=None) # Kurtosis

  return np.hstack([mean, median, rms_vector, max, min, first_quantile, third_quantile, interquantile_range, std, skew, kurtosis])


def extract_features_mine(x, sr=22000, n_fft=2048, hop_length=512):
  """
  Computes various handcrafted features of the input array 
  inputs:
    - array: the input signal
    - sr: sampling rate
    - n_fft: size of the FFT
    - hop_length: hop length
  outputs:
    - duration: the duration of the signal
    - period: the period of the signal
    - onset_frames: vector containing the onset strength envelope
    - tempo: the tempo of the signal
    - spectral_rolloff: the roll-off frequency for each frame of audio
    - zero_crossing: the sum of the zero crossings of audio
    - rms: the rms of the signal
    - spectral_centroid: the spectral centroid of the audio
    - mfcc_13: the MFCC sequence
    - mfcc_delta: the delta matrix of data at the first order
    - mfcc_delta2: the delta matrix of data at the second order
  """
  duration = get_duration(x)
  onset_frames = get_onset_frames(x)
  period = get_period()
  tempo = get_tempo(x)
  spectral_rolloff = get_spectral_rolloff(x)
  zero_crossing = get_zero_crossing(x)
  rms = get_rms(x) #[shape=(1, t)]
  spectral_centroid = get_spectral_centroid(x) # [shape=(1, t)]
  mfcc_13 = get_mfcc_13(x) # [shape=(13, t)]
  mfcc_delta = get_mfcc_delta(mfcc_13) # [shape=(13, t)]
  mfcc_delta2 = get_mfcc_delta2(mfcc_13) # [shape=(13, t)]

  return duration, period, onset_frames, tempo, spectral_rolloff, zero_crossing, rms, spectral_centroid, mfcc_13, mfcc_delta, mfcc_delta2

def feature_extraction(audio_path, large_stats=True):
  """
  Computes a normalized feature vector
  inputs:
    - audio_path: the input signal
    - large_stats: the detailed versions of statistical components
  outputs:
    - a numpy hstack of the various normalized features
  """
  X, sr = librosa.load(audio_path, sr = SAMPLING_RATE)
  Xt, index = librosa.effects.trim(X, top_db=TOP_DB)

  if Xt.shape[0] < 5*SAMPLING_RATE:
    Xt=np.pad(Xt,int(np.ceil((5*SAMPLING_RATE-Xt.shape[0])/2)), mode='reflect')
  else:
    Xt=Xt[:5*SAMPLING_RATE]
  
  dur, period, onset, tempo, spec_rolloff, zero_crossing, rms, spec_centroid, mfcc_13, mfcc_delta, mfcc_delta2 = extract_features_mine(Xt, sr=SAMPLING_RATE, n_fft=2048, hop_length=512)
  
  if large_stats == True:
    stats_rms = get_stats(rms)
    stats_spec_centroid = get_stats(spec_centroid)
    stats_mfcc = get_stats(mfcc_13)
    stats_mfcc_delta = get_stats(mfcc_delta)
    stats_mfcc_delta2 = get_stats(mfcc_delta2)
  else:
    stats_rms = get_stats2(rms)
    stats_spec_centroid = get_stats2(spec_centroid)
    stats_mfcc = get_stats2(mfcc_13)
    stats_mfcc_delta = get_stats2(mfcc_delta)
    stats_mfcc_delta2 = get_stats2(mfcc_delta2)
   
  vector = np.hstack([dur, period, onset, tempo, spec_rolloff, zero_crossing, stats_rms, stats_spec_centroid, stats_mfcc, stats_mfcc_delta, stats_mfcc_delta2]).reshape(-1, 1)
  norm = vector.shape[0]
  return vector/norm # Normalized vectors

def GenerateVectors(path, dataset_type, LARGE_STATS=True):
  """
  Computes the feature vectors of all files in the path
  inputs:
    - path: the file location containing the audio files
    - dataset_type: the type of dataset (train/test/val)
  outputs:
    - x_2: a numpy array containing all the feature vectors of all the signals
  """
  positive_paths = []
  negative_paths = []
  for entry in os.scandir(os.path.join(path, os.path.join(dataset_type, 'pos'))):
    if entry.is_file():
      positive_paths.append(entry.path)
  for entry in os.scandir(os.path.join(path, os.path.join(dataset_type, 'neg'))):
    if entry.is_file():
      negative_paths.append(entry.path)
        
  path_to_audio_vec_p = list(map(lambda x: feature_extraction(x, True), positive_paths))
  path_to_audio_vec_n = list(map(lambda x: feature_extraction(x, True), negative_paths))
        
  x_2_list = path_to_audio_vec_p.copy()
  x_2_list.extend(path_to_audio_vec_n)

  random.shuffle(x_2_list, myfunction)

  x_2 = np.array(x_2_list)
  
  return x_2