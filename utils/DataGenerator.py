# -*- coding: utf-8 -*-
"""DataGenerator

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YC5JRyMZCHNWbpTAO6Fq9OmZhuU6M1MK
"""

import pandas
import numpy as np
import matplotlib.pyplot as plt
import os
import librosa
import librosa.display
import tensorflow as tf
import random
from utils import Parameters

SAMPLING_RATE = Parameters.SAMPLING_RATE
DURATION = Parameters.DURATION
NUM_MELS = Parameters.NUM_MELS
FMAX = Parameters.FMAX
TOP_DB = Parameters.TOP_DB
EPS = Parameters.EPS

def create_mel(path, sr = SAMPLING_RATE, n_mels=512, fmax = 10000, top_db=30, eps = 1e-6, plot = False):
  """
  Creates a Mel Spectrogram from a given audio sample. This code standardizes 
  important aspects such as sampling rate, duration, normalization, and other
  related aspects of the audio
  inputs:
    - path: the file location of the audio sample
    - sr: sampling rate with which to sample the audio
    - n_mels: length of the FFT window
    - fmax: the maximum frequency
    - top_db: the threshold (in decibels) below reference to consider as 
      silence
    - eps: variation
    - plot: a boolean which decides whether to create a plot or not

  Returns: a scaled and normalized mel spectrogram array
  """
  y , sr = librosa.load(path, sr=sr)
  yt, index = librosa.effects.trim(y, top_db=top_db)

  if yt.shape[0] < DURATION*SAMPLING_RATE:
    yt=np.pad(yt,int(np.ceil((DURATION*sr-yt.shape[0])/2)), mode='reflect')
  else:
    yt=yt[:DURATION*sr]

  # S = librosa.feature.mfcc(y=yt, sr=SAMPLING_RATE,n_mfcc=13)
  
  # mean = S.mean()
  # std = S.std()
  # S_norm = (S - mean) / (std + eps)

  if plot:
    plt.figure()
    librosa.display.specshow(S)
    plt.colorbar()


  if plot:
    plt.figure()
    librosa.display.specshow(S_norm)
    plt.colorbar()

  S = librosa.feature.melspectrogram(y=yt, sr=sr, n_mels=n_mels, fmax=fmax)
  S_dB = librosa.power_to_db(S, ref=np.max)
  mean = S_dB.mean()
  std = S_dB.std()
  S_dB_norm = (S_dB - mean) / (std + eps)
  
  S_dB_min, S_dB_max = S_dB_norm.min(), S_dB_norm.max()
  S_dB_scaled = 255 * (S_dB_norm - S_dB_min) / (S_dB_max - S_dB_min)
  S_dB_scaled = S_dB_scaled.astype(np.uint8)
  
  #if plot:
  #  plt.figure()
  #  librosa.display.specshow(S_dB_scaled)
  #  plt.colorbar()

  return S_dB_scaled.reshape(S_dB_scaled.shape[0], S_dB_scaled.shape[1], 1)

def myfunction():
  """
  Returns the number 0.35. This is used in the random.shuffle() function
  inputs:
    - N/A
  Returns: the number 0.35
  """
  return 0.35

def DataGenerator(sr, n_mels, fmax, top_db, eps, seed, path, dataset_type='train'):
  """
  Creates Mel Spectrograms for all the files in the path
  inputs:
    - path: the file location of the audio sample
    - sr: sampling rate with which to sample the audio
    - n_mels: length of the FFT window
    - fmax: the maximum frequency
    - seed: the seed with which to randomly shuffle
    - top_db: the threshold (in decibels) below reference to consider as 
      silence
    - eps: variation
    - dataset_type: the type of data set such as train/test/val. 
  output:
    - x_1: the collection of mel spectrograms of positive and negative samples
    - y_1: a list of 1's and 0's representing positive and negative samples
  """
  positive_paths = []
  negative_paths = []
  for entry in os.scandir(os.path.join(path, os.path.join(dataset_type, 'pos'))):
    if entry.is_file():
      #if librosa.get_duration(filename=entry) > 0:
      positive_paths.append(entry.path)
        
  for entry in os.scandir(os.path.join(path, os.path.join(dataset_type, 'neg'))):
    if entry.is_file():
      #if librosa.get_duration(filename=entry) > 0:
      negative_paths.append(entry.path)


  path_to_audio_p = list(map(lambda x: create_mel(x, SAMPLING_RATE, NUM_MELS, FMAX, TOP_DB, EPS, plot=False), positive_paths))
  pos_labels_ds = [1 for i in positive_paths]

  path_to_audio_n = list(map(lambda x: create_mel(x, SAMPLING_RATE, NUM_MELS, FMAX, TOP_DB, EPS, plot=False), negative_paths))
  neg_labels_ds = [0 for i in negative_paths]

  x_list = path_to_audio_p.copy()
  y_list = pos_labels_ds.copy()

  x_list.extend(path_to_audio_n)
  y_list.extend(neg_labels_ds)

  random.shuffle(x_list, myfunction)
  random.shuffle(y_list, myfunction)

  x_1 = np.array(x_list)
  y_1 = np.array(y_list)

  return x_1, y_1


def Get_matrix_inputs(new_audio_path, coswara_audio_path, audio_path, load=True):
  """
  Function to get the spectrogram images 
  Parameters
  ----------
  new_audio_path: str
    audio path of the new dataset
  
  coswara_audio_path:str
    audio path of the coswara dataset
  
  audio_path:str
    audio path to use

  load: bool
    Whether to load or generate vectors
      True: Load vectors
      False: Generate vectors: Warning takes around 1hr

  Returns
  -------
  x_test: np array
    testing images for the model

  y_train: np array
    labels for testing dataset

  x_train: np array
    training images for the model

  y_train: np array
    labels for testing dataset
  
  x_val: np array
    validatoin images for the model

  y_val: np array
    labels for validation dataset
  """
  if load:
    if audio_path == coswara_audio_path:
      x_train = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Train_Spec_Coswara.npy') # JUST LOAD THE VECTORS
      y_train = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Train_Spec_Coswara.npy')
      x_test = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Test_Spec_Coswara.npy')
      y_test = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Test_Spec_Coswara.npy')
      x_val = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Val_Spec_Coswara.npy')
      y_val = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Val_Spec_Coswara.npy')
    elif audio_path == new_audio_path:
      x_train = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Train_Spec_NewDataset.npy') # JUST LOAD THE VECTORS
      y_train = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Train_Spec_NewDataset.npy')
      x_test = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Test_Spec_NewDataset.npy')
      y_test = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Test_Spec_NewDataset.npy')
      x_val = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Val_Spec_NewDataset.npy')
      y_val = np.load('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Val_Spec_NewDataset.npy')
  else:
    x_train, y_train = DataGenerator(SAMPLING_RATE, NUM_MELS, FMAX, TOP_DB, EPS, SEED, audio_path, 'train') #### DO NOT RUN
    x_test, y_test = DataGenerator(SAMPLING_RATE, NUM_MELS, FMAX, TOP_DB, EPS, SEED, audio_path, 'test')
    x_val, y_val = DataGenerator(SAMPLING_RATE, NUM_MELS, FMAX, TOP_DB, EPS, SEED, audio_path, 'val')
    if audio_path == coswara_audio_path:
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Train_Spec_Coswara', x_train)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Train_Spec_Coswara', y_train)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Test_Spec_Coswara', x_test)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Test_Spec_Coswara', y_test)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Val_Spec_Coswara', x_val)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Val_Spec_Coswara', y_val)
    elif audio_path == new_audio_path:
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Train_Spec_NewDataset', x_train)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Train_Spec_NewDataset', y_train)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Test_Spec_NewDataset', x_test)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Test_Spec_NewDataset', y_test)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/X_Val_Spec_NewDataset', x_val)
      np.save('/content/gdrive/MyDrive/DSCI400/Saved_Variables/Y_Val_Spec_NewDataset', y_val)
  
  return (x_train, y_train.reshape((-1, 1)), x_test, y_test.reshape((-1, 1)), x_val, y_val.reshape((-1, 1)))


def Data_Viz(n_row, n_cols, x_test, y_test):
  """
  Visualizer of the DataGenerator Function
  Parameters:
  ----------
  n_row: int
    Number of rows to show
  n_cols: int
    Number of columns to show
  x_test: np array
    Matrix of MFCC featuers
  y_test: np array
    Array of labels 1-positive, 0-negative
  """
  assert (len(x_test.shape)==4), 'Input shape should be a N number of matrices'
  assert (len(y_test.shape)==2), 'Input shape should be a vector of shape (N, 1)'

  #Generate spectrograms for each audio sample with classification
  rows = n_row
  cols = n_cols
  n = rows*cols
  fig, axes = plt.subplots(rows, cols, figsize=(16, 12))

  for i, (audio, status) in list(enumerate(zip(x_test, y_test)))[0:n]:
    r = i // cols
    c = i % cols
    ax = axes[r][c]

    plt.subplot(ax)
    librosa.display.specshow(audio.reshape(512, 215,))
    plt.colorbar()

    if status == 1:
      label = 'Positive'
    else:
      label = 'Negative'
    ax.set_title(label)
  plt.show()














